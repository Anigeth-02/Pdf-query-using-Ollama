{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61562457",
   "metadata": {},
   "source": [
    "RAG(Retrieval-Augmented Generation)\n",
    "\n",
    "It combines two separate AI capabilities:\n",
    "\n",
    "->Retrieval â†’ Finding relevant information from a knowledge base (like your PDF, FAISS, or database)\n",
    "\n",
    "->Generation â†’ Using a language model (like Llama 3.1, GPT, etc.) to generate a natural language answer\n",
    "\n",
    "So instead of relying only on the modelâ€™s internal memory or training data (which might be outdated or incomplete),\n",
    "the model is augmented with external retrieved knowledge â€” thatâ€™s why we call it Retrieval-Augmented Generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96c621",
   "metadata": {},
   "source": [
    "Without RAG vs With RAG\n",
    "\n",
    "1.Without RAG (Pure Generation)\n",
    "\n",
    "If you just ask:\n",
    "\n",
    "â€œSummarize the main highlights of the 2024 Indian budget.â€ to a plain LLM (like Llama or GPT),\n",
    "the model answers from its training data, which:\n",
    "\n",
    "->Might be outdated\n",
    "\n",
    "->Might not contain your specific document\n",
    "\n",
    "->Might hallucinate (make up info)\n",
    "\n",
    "So the model guesses rather than knowing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d90d02",
   "metadata": {},
   "source": [
    "2.With RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "When you use RAG, the pipeline does this:\n",
    "\n",
    "->Retrieve relevant text from external sources (like your PDF â†’ FAISS)\n",
    "\n",
    "->Augment the user question with that retrieved text (context)\n",
    "\n",
    "->Generate the answer using the model â€” based only on that retrieved context\n",
    "\n",
    "Thatâ€™s why itâ€™s called Retrieval + Augmentation + Generation.\n",
    "\n",
    "In short:\n",
    "\n",
    "The model doesnâ€™t guess anymore â€” it reads the right info first, then answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83040da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651de561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import OllamaLLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06bdb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = r\"C:\\Users\\ANIGETH\\Downloads\\Langchain_project\\pdf_query_ollama\\budget_speech.pdf\"\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"   # 384-dim\n",
    "OLLAMA_MODEL = \"llama3.1\"                                # already installed via `ollama pull llama3.1`\n",
    "INDEX_DIR = \"./faiss_index\"                               # folder to persist FAISS\n",
    "CHUNK_SIZE = 800\n",
    "CHUNK_OVERLAP = 50\n",
    "TOP_K = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc2242c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loaded 60 pages\n"
     ]
    }
   ],
   "source": [
    "# Loadinf PDF \n",
    "assert Path(PDF_PATH).exists(), f\"PDF not found at: {PDF_PATH}\"\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "docs = loader.load()\n",
    "print(f\"ðŸ“„ Loaded {len(docs)} pages\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464f7093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ Split into 146 chunks\n"
     ]
    }
   ],
   "source": [
    "# Splitting into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "documents = splitter.split_documents(docs)\n",
    "print(f\"âœ‚ï¸ Split into {len(documents)} chunks\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e9b3169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANIGETH\\Downloads\\Langchain_project\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Embedding\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1364bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ†• Built FAISS index at ./faiss_index\n"
     ]
    }
   ],
   "source": [
    "# Load FAISS(Facebook AI Similarity Search)index\n",
    "if not Path(INDEX_DIR).exists():\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    vectorstore.save_local(INDEX_DIR)\n",
    "    print(f\"ðŸ†• Built FAISS index at {INDEX_DIR}\")\n",
    "else:\n",
    "    vectorstore = FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(f\"ðŸ“¦ Loaded existing FAISS index from {INDEX_DIR}\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f9ce45d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # LLM (LOCAL OLLAMA)\n",
    "llm = OllamaLLM(model=OLLAMA_MODEL)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Prompt: you can tweak tone/formatting here\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"You are a helpful assistant. Use ONLY the context to answer clearly and concisely.\n",
    "If the answer is not in the context, say \"I don't know from the provided document.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e162d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant chunks from FAISS and answer using Llama (Ollama).\"\"\"\n",
    "    retrieved = retriever.invoke(query)\n",
    "    context = \"\\n\\n\".join(d.page_content for d in retrieved)\n",
    "    msg = prompt.format(context=context, question=query)\n",
    "    # OllamaLLM takes a string; returns a string\n",
    "    raw = llm.invoke(str(msg))\n",
    "    return parser.invoke(raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62d65385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Answer:\n",
      " The main highlights of the Budget Speech are:\n",
      "\n",
      "1. Accelerate growth\n",
      "2. Secure inclusive development\n",
      "3. Invigorate private sector investments\n",
      "4. Uplift household sentiments\n",
      "5. Enhance spending power of India's rising middle class\n",
      "6. Transformative work done in first two terms guides the government to march forward\n"
     ]
    }
   ],
   "source": [
    "question = \"Summarize the main highlights of the budget speech\"\n",
    "answer = ask(question)\n",
    "print(\"\\n Answer:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c7ef4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Answer:\n",
      " A Centre of Excellence in Artificial Intelligence (AI) for education will be set up with a total outlay of ` 500 crore.\n"
     ]
    }
   ],
   "source": [
    "question = \"Maaking any invetsment on AI\"\n",
    "answer = ask(question)\n",
    "print(\"\\n Answer:\\n\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
